{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mani_skill in ./myenv/lib64/python3.12/site-packages (3.0.0b5)\n",
      "Collecting tyro\n",
      "  Downloading tyro-0.8.5-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting diffusers\n",
      "  Downloading diffusers-0.29.2-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting sk-video\n",
      "  Downloading sk_video-1.1.10-py2.py3-none-any.whl.metadata (1.0 kB)\n",
      "Requirement already satisfied: numpy>=1.22 in ./myenv/lib64/python3.12/site-packages (from mani_skill) (2.0.0)\n",
      "Requirement already satisfied: scipy in ./myenv/lib64/python3.12/site-packages (from mani_skill) (1.13.1)\n",
      "Requirement already satisfied: dacite in ./myenv/lib64/python3.12/site-packages (from mani_skill) (1.8.1)\n",
      "Requirement already satisfied: gymnasium==0.29.1 in ./myenv/lib64/python3.12/site-packages (from mani_skill) (0.29.1)\n",
      "Requirement already satisfied: sapien==3.0.0.b1 in ./myenv/lib64/python3.12/site-packages (from mani_skill) (3.0.0b1)\n",
      "Requirement already satisfied: h5py in ./myenv/lib64/python3.12/site-packages (from mani_skill) (3.11.0)\n",
      "Requirement already satisfied: pyyaml in ./myenv/lib64/python3.12/site-packages (from mani_skill) (6.0.1)\n",
      "Requirement already satisfied: tqdm in ./myenv/lib64/python3.12/site-packages (from mani_skill) (4.66.4)\n",
      "Requirement already satisfied: GitPython in ./myenv/lib64/python3.12/site-packages (from mani_skill) (3.1.43)\n",
      "Requirement already satisfied: tabulate in ./myenv/lib64/python3.12/site-packages (from mani_skill) (0.9.0)\n",
      "Requirement already satisfied: transforms3d in ./myenv/lib64/python3.12/site-packages (from mani_skill) (0.4.2)\n",
      "Requirement already satisfied: trimesh in ./myenv/lib64/python3.12/site-packages (from mani_skill) (4.4.1)\n",
      "Requirement already satisfied: rtree in ./myenv/lib64/python3.12/site-packages (from mani_skill) (1.2.0)\n",
      "Requirement already satisfied: imageio in ./myenv/lib64/python3.12/site-packages (from mani_skill) (2.34.1)\n",
      "Requirement already satisfied: IPython in ./myenv/lib64/python3.12/site-packages (from mani_skill) (8.25.0)\n",
      "Requirement already satisfied: huggingface-hub in ./myenv/lib64/python3.12/site-packages (from mani_skill) (0.23.4)\n",
      "Requirement already satisfied: mplib>=0.1.1 in ./myenv/lib64/python3.12/site-packages (from mani_skill) (0.1.1)\n",
      "Requirement already satisfied: fast-kinematics==0.2.2 in ./myenv/lib64/python3.12/site-packages (from mani_skill) (0.2.2)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in ./myenv/lib64/python3.12/site-packages (from gymnasium==0.29.1->mani_skill) (3.0.0)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in ./myenv/lib64/python3.12/site-packages (from gymnasium==0.29.1->mani_skill) (4.12.2)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in ./myenv/lib64/python3.12/site-packages (from gymnasium==0.29.1->mani_skill) (0.0.4)\n",
      "Requirement already satisfied: requests>=2.22 in ./myenv/lib64/python3.12/site-packages (from sapien==3.0.0.b1->mani_skill) (2.32.3)\n",
      "Requirement already satisfied: lxml in ./myenv/lib64/python3.12/site-packages (from sapien==3.0.0.b1->mani_skill) (5.2.2)\n",
      "Requirement already satisfied: networkx in ./myenv/lib64/python3.12/site-packages (from sapien==3.0.0.b1->mani_skill) (3.3)\n",
      "Requirement already satisfied: pyperclip in ./myenv/lib64/python3.12/site-packages (from sapien==3.0.0.b1->mani_skill) (1.9.0)\n",
      "Requirement already satisfied: opencv-python>=4.0 in ./myenv/lib64/python3.12/site-packages (from sapien==3.0.0.b1->mani_skill) (4.10.0.84)\n",
      "Collecting docstring-parser>=0.16 (from tyro)\n",
      "  Downloading docstring_parser-0.16-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting rich>=11.1.0 (from tyro)\n",
      "  Downloading rich-13.7.1-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting shtab>=1.5.6 (from tyro)\n",
      "  Downloading shtab-1.7.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting importlib-metadata (from diffusers)\n",
      "  Downloading importlib_metadata-8.0.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: filelock in ./myenv/lib64/python3.12/site-packages (from diffusers) (3.15.3)\n",
      "Collecting regex!=2019.12.17 (from diffusers)\n",
      "  Downloading regex-2024.5.15-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting safetensors>=0.3.1 (from diffusers)\n",
      "  Downloading safetensors-0.4.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: Pillow in ./myenv/lib64/python3.12/site-packages (from diffusers) (10.3.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./myenv/lib64/python3.12/site-packages (from huggingface-hub->mani_skill) (2024.6.0)\n",
      "Requirement already satisfied: packaging>=20.9 in ./myenv/lib64/python3.12/site-packages (from huggingface-hub->mani_skill) (24.1)\n",
      "Requirement already satisfied: toppra>=0.4.0 in ./myenv/lib64/python3.12/site-packages (from mplib>=0.1.1->mani_skill) (0.6.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./myenv/lib64/python3.12/site-packages (from requests>=2.22->sapien==3.0.0.b1->mani_skill) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./myenv/lib64/python3.12/site-packages (from requests>=2.22->sapien==3.0.0.b1->mani_skill) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./myenv/lib64/python3.12/site-packages (from requests>=2.22->sapien==3.0.0.b1->mani_skill) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./myenv/lib64/python3.12/site-packages (from requests>=2.22->sapien==3.0.0.b1->mani_skill) (2024.6.2)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=11.1.0->tyro)\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./myenv/lib64/python3.12/site-packages (from rich>=11.1.0->tyro) (2.18.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in ./myenv/lib64/python3.12/site-packages (from GitPython->mani_skill) (4.0.11)\n",
      "Requirement already satisfied: imageio-ffmpeg in ./myenv/lib64/python3.12/site-packages (from imageio[ffmpeg]->mani_skill) (0.5.1)\n",
      "Requirement already satisfied: psutil in ./myenv/lib64/python3.12/site-packages (from imageio[ffmpeg]->mani_skill) (6.0.0)\n",
      "Collecting zipp>=0.5 (from importlib-metadata->diffusers)\n",
      "  Downloading zipp-3.19.2-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: decorator in ./myenv/lib64/python3.12/site-packages (from IPython->mani_skill) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in ./myenv/lib64/python3.12/site-packages (from IPython->mani_skill) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in ./myenv/lib64/python3.12/site-packages (from IPython->mani_skill) (0.1.7)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in ./myenv/lib64/python3.12/site-packages (from IPython->mani_skill) (3.0.47)\n",
      "Requirement already satisfied: stack-data in ./myenv/lib64/python3.12/site-packages (from IPython->mani_skill) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in ./myenv/lib64/python3.12/site-packages (from IPython->mani_skill) (5.14.3)\n",
      "Requirement already satisfied: pexpect>4.3 in ./myenv/lib64/python3.12/site-packages (from IPython->mani_skill) (4.9.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in ./myenv/lib64/python3.12/site-packages (from gitdb<5,>=4.0.1->GitPython->mani_skill) (5.0.1)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in ./myenv/lib64/python3.12/site-packages (from jedi>=0.16->IPython->mani_skill) (0.8.4)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in ./myenv/lib64/python3.12/site-packages (from pexpect>4.3->IPython->mani_skill) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in ./myenv/lib64/python3.12/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->IPython->mani_skill) (0.2.13)\n",
      "Requirement already satisfied: matplotlib in ./myenv/lib64/python3.12/site-packages (from toppra>=0.4.0->mplib>=0.1.1->mani_skill) (3.9.0)\n",
      "Requirement already satisfied: setuptools in ./myenv/lib64/python3.12/site-packages (from imageio-ffmpeg->imageio[ffmpeg]->mani_skill) (70.1.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in ./myenv/lib64/python3.12/site-packages (from stack-data->IPython->mani_skill) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in ./myenv/lib64/python3.12/site-packages (from stack-data->IPython->mani_skill) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in ./myenv/lib64/python3.12/site-packages (from stack-data->IPython->mani_skill) (0.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in ./myenv/lib64/python3.12/site-packages (from asttokens>=2.1.0->stack-data->IPython->mani_skill) (1.16.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./myenv/lib64/python3.12/site-packages (from matplotlib->toppra>=0.4.0->mplib>=0.1.1->mani_skill) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in ./myenv/lib64/python3.12/site-packages (from matplotlib->toppra>=0.4.0->mplib>=0.1.1->mani_skill) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./myenv/lib64/python3.12/site-packages (from matplotlib->toppra>=0.4.0->mplib>=0.1.1->mani_skill) (4.53.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./myenv/lib64/python3.12/site-packages (from matplotlib->toppra>=0.4.0->mplib>=0.1.1->mani_skill) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./myenv/lib64/python3.12/site-packages (from matplotlib->toppra>=0.4.0->mplib>=0.1.1->mani_skill) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./myenv/lib64/python3.12/site-packages (from matplotlib->toppra>=0.4.0->mplib>=0.1.1->mani_skill) (2.9.0.post0)\n",
      "Downloading tyro-0.8.5-py3-none-any.whl (103 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.4/103.4 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading diffusers-0.29.2-py3-none-any.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading sk_video-1.1.10-py2.py3-none-any.whl (2.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading docstring_parser-0.16-py3-none-any.whl (36 kB)\n",
      "Downloading regex-2024.5.15-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (788 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m788.8/788.8 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading rich-13.7.1-py3-none-any.whl (240 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.7/240.7 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.4.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading shtab-1.7.1-py3-none-any.whl (14 kB)\n",
      "Downloading importlib_metadata-8.0.0-py3-none-any.whl (24 kB)\n",
      "Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading zipp-3.19.2-py3-none-any.whl (9.0 kB)\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: zipp, shtab, safetensors, regex, mdurl, docstring-parser, sk-video, markdown-it-py, importlib-metadata, rich, diffusers, tyro\n",
      "Successfully installed diffusers-0.29.2 docstring-parser-0.16 importlib-metadata-8.0.0 markdown-it-py-3.0.0 mdurl-0.1.2 regex-2024.5.15 rich-13.7.1 safetensors-0.4.3 shtab-1.7.1 sk-video-1.1.10 tyro-0.8.5 zipp-3.19.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade mani_skill tyro diffusers sk-video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, Sequence, Dict, Union, Optional, Callable\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "\n",
    "from diffusers.schedulers.scheduling_ddpm import DDPMScheduler\n",
    "from diffusers.training_utils import EMAModel\n",
    "from diffusers.optimization import get_scheduler\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import h5py\n",
    "\n",
    "import gymnasium as gym\n",
    "\n",
    "from mani_skill.utils.io_utils import load_json\n",
    "import mani_skill.envs\n",
    "from mani_skill.trajectory.dataset import ManiSkillTrajectoryDataset\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import cv2\n",
    "from skvideo.io import vwrite\n",
    "from IPython.display import Video\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All demonstrations will be downloaded. This may take a while.\n",
      "Downloading demonstrations to /home/jangruhnert/.maniskill/demos - 1/5, PickCube-v1\n",
      "19.1Mit [00:02, 8.72Mit/s]                                                      \n",
      "Downloading demonstrations to /home/jangruhnert/.maniskill/demos - 2/5, PushCube-v1\n",
      "9.27Mit [00:01, 5.45Mit/s]                                                      \n",
      "Downloading demonstrations to /home/jangruhnert/.maniskill/demos - 3/5, StackCube-v1\n",
      "16.8Mit [00:01, 9.22Mit/s]                                                      \n",
      "Downloading demonstrations to /home/jangruhnert/.maniskill/demos - 4/5, PegInsertionSide-v1\n",
      "35.6Mit [00:03, 11.0Mit/s]                                                      \n",
      "Downloading demonstrations to /home/jangruhnert/.maniskill/demos - 5/5, PlugCharger-v1\n",
      "24.3Mit [00:02, 8.95Mit/s]                                                      \n"
     ]
    }
   ],
   "source": [
    "#!python -m mani_skill.utils.download_demo all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0step [00:00, ?step/s]Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/home/jangruhnert/Documents/GitHub/uni-dll-nr2/myenv/lib64/python3.12/site-packages/mani_skill/trajectory/replay_trajectory.py\", line 610, in <module>\n",
      "    main(parse_args())\n",
      "  File \"/home/jangruhnert/Documents/GitHub/uni-dll-nr2/myenv/lib64/python3.12/site-packages/mani_skill/trajectory/replay_trajectory.py\", line 604, in main\n",
      "    _main(args)\n",
      "  File \"/home/jangruhnert/Documents/GitHub/uni-dll-nr2/myenv/lib64/python3.12/site-packages/mani_skill/trajectory/replay_trajectory.py\", line 415, in _main\n",
      "    env = gym.make(env_id, **env_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jangruhnert/Documents/GitHub/uni-dll-nr2/myenv/lib64/python3.12/site-packages/gymnasium/envs/registration.py\", line 802, in make\n",
      "    env = env_creator(**env_spec_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jangruhnert/Documents/GitHub/uni-dll-nr2/myenv/lib64/python3.12/site-packages/mani_skill/utils/registration.py\", line 82, in make\n",
      "    env = env_spec.make(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jangruhnert/Documents/GitHub/uni-dll-nr2/myenv/lib64/python3.12/site-packages/mani_skill/utils/registration.py\", line 35, in make\n",
      "    return self.cls(**_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jangruhnert/Documents/GitHub/uni-dll-nr2/myenv/lib64/python3.12/site-packages/mani_skill/envs/tasks/tabletop/pick_cube.py\", line 27, in __init__\n",
      "    super().__init__(*args, robot_uids=robot_uids, **kwargs)\n",
      "  File \"/home/jangruhnert/Documents/GitHub/uni-dll-nr2/myenv/lib64/python3.12/site-packages/mani_skill/envs/sapien_env.py\", line 274, in __init__\n",
      "    obs, _ = self.reset(seed=2022, options=dict(reconfigure=True))\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jangruhnert/Documents/GitHub/uni-dll-nr2/myenv/lib64/python3.12/site-packages/mani_skill/envs/sapien_env.py\", line 684, in reset\n",
      "    self._reconfigure(options)\n",
      "  File \"/home/jangruhnert/Documents/GitHub/uni-dll-nr2/myenv/lib64/python3.12/site-packages/mani_skill/envs/sapien_env.py\", line 542, in _reconfigure\n",
      "    self._setup_scene()\n",
      "  File \"/home/jangruhnert/Documents/GitHub/uni-dll-nr2/myenv/lib64/python3.12/site-packages/mani_skill/envs/sapien_env.py\", line 927, in _setup_scene\n",
      "    sapien.Scene([self.physx_system, sapien.render.RenderSystem()])\n",
      "                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: invalid PCI string\n",
      "0step [00:00, ?step/s]\n"
     ]
    }
   ],
   "source": [
    "# Replay demonstrations with control_mode=pd_joint_pos\n",
    "#!python -m mani_skill.trajectory.replay_trajectory \\\n",
    "#  --traj-path /content/drive/MyDrive/Data/Training/demos/PickCube-v1/rl/trajectory.h5 \\\n",
    "#  --save-traj --target-control-mode pd_joint_pos \\\n",
    "#  --obs-mode state --num-procs 10\n",
    "\n",
    "!python -m mani_skill.trajectory.replay_trajectory \\\n",
    "  --traj-path ./data/PickCube-v1/rl/trajectory.h5 \\\n",
    "  --save-traj \\\n",
    "  --obs-mode pointcloud \\\n",
    "  --sim-backend cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "from mani_skill.utils import common\n",
    "from mani_skill.utils.io_utils import load_json\n",
    "\n",
    "\n",
    "# loads h5 data into memory for faster access\n",
    "def load_h5_data(data):\n",
    "    out = dict()\n",
    "    for k in data.keys():\n",
    "        if isinstance(data[k], h5py.Dataset):\n",
    "            out[k] = data[k][:]\n",
    "        else:\n",
    "            out[k] = load_h5_data(data[k])\n",
    "    return out\n",
    "\n",
    "def create_sample_indices(episode_ends: np.ndarray, sequence_length: int, pad_before: int = 0, pad_after: int = 0):\n",
    "    indices = []\n",
    "    episode_length = 0\n",
    "    for i in range(len(episode_ends)):\n",
    "        if not episode_ends[i]:\n",
    "            episode_length += 1\n",
    "        else:\n",
    "            start_idx = 0 if i == 0 else i\n",
    "            min_start = -pad_before\n",
    "            max_start = episode_length - sequence_length + pad_after\n",
    "\n",
    "            for idx in range(min_start, max_start + 1):\n",
    "                buffer_start_idx = max(idx, 0) + start_idx\n",
    "                buffer_end_idx = min(idx + sequence_length, episode_length) + start_idx\n",
    "                start_offset = buffer_start_idx - (idx + start_idx)\n",
    "                end_offset = (idx + sequence_length + start_idx) - buffer_end_idx\n",
    "                sample_start_idx = 0 + start_offset\n",
    "                sample_end_idx = sequence_length - end_offset\n",
    "                indices.append([buffer_start_idx, buffer_end_idx, sample_start_idx, sample_end_idx])\n",
    "    return np.array(indices)\n",
    "\n",
    "\n",
    "def sample_sequence(train_data, sequence_length, buffer_start_idx, buffer_end_idx, sample_start_idx, sample_end_idx):\n",
    "    result = []\n",
    "  \n",
    "    sample = train_data[buffer_start_idx:buffer_end_idx]\n",
    "    data = np.zeros(shape=(sequence_length,) + train_data.shape[1:], dtype=train_data.dtype)\n",
    "    if sample_start_idx > 0:\n",
    "        data[:sample_start_idx] = sample[0]\n",
    "    if sample_end_idx < sequence_length:\n",
    "        data[sample_end_idx:] = sample[-1]\n",
    "    data[sample_start_idx:sample_end_idx] = sample\n",
    "    result.append(data)\n",
    "  \n",
    "    return np.vstack(result)\n",
    "\n",
    "# normalize data\n",
    "def get_data_stats(data):\n",
    "  data = data.reshape(-1,data.shape[-1])\n",
    "  stats = {\n",
    "    'min': np.min(data, axis=0),\n",
    "    'max': np.max(data, axis=0)\n",
    "  }\n",
    "  return stats\n",
    "\n",
    "def normalize_data(obs, terminated):\n",
    "    episode_min = 0\n",
    "    episode_max = 0\n",
    "    for i in range(len(terminated)):\n",
    "        if terminated[i]:\n",
    "            episode_max = i\n",
    "            if episode_min != episode_max:   \n",
    "                counter = (obs[episode_min:episode_max] - obs[episode_min:episode_max].min(axis=0))\n",
    "                divider = (obs[episode_min:episode_max].max(axis=0) - obs[episode_min:episode_max].min(axis=0))\n",
    "                obs[episode_min:episode_max] =  counter / divider\n",
    "            episode_min = i + 1\n",
    "        else:\n",
    "            episode_max = i\n",
    "\n",
    "class CustomManiSkillTrajectoryDataset(Dataset):\n",
    "    \"\"\"\n",
    "    A general torch Dataset you can drop in and use immediately with just about any trajectory .h5 data generated from ManiSkill.\n",
    "    This class simply is a simple starter code to load trajectory data easily, but does not do any data transformation or anything\n",
    "    advanced. We recommend you to copy this code directly and modify it for more advanced use cases\n",
    "\n",
    "    Args:\n",
    "        dataset_file (str): path to the .h5 file containing the data you want to load\n",
    "        load_count (int): the number of trajectories from the dataset to load into memory. If -1, will load all into memory\n",
    "        success_only (bool): whether to skip trajectories that are not successful in the end. Default is false\n",
    "        device: The location to save data to. If None will store as numpy (the default), otherwise will move data to that device\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, dataset_file: str, pred_horizon: int, obs_horizon: int, action_horizon:int, load_count=-1, success_only: bool = False, normalize: bool = False, device=None\n",
    "    ) -> None:\n",
    "        self.dataset_file = dataset_file\n",
    "        self.pred_horizon = pred_horizon\n",
    "        self.obs_horizon = obs_horizon\n",
    "        self.action_horizon = action_horizon\n",
    "        self.normalize = normalize\n",
    "        self.device = device\n",
    "        self.data = h5py.File(dataset_file, \"r\")\n",
    "        json_path = dataset_file.replace(\".h5\", \".json\")\n",
    "        self.json_data = load_json(json_path)\n",
    "        self.episodes = self.json_data[\"episodes\"]\n",
    "        self.env_info = self.json_data[\"env_info\"]\n",
    "        self.env_id = self.env_info[\"env_id\"]\n",
    "        self.env_kwargs = self.env_info[\"env_kwargs\"]\n",
    "\n",
    "        self.obs = None\n",
    "        self.actions = []\n",
    "        self.terminated = []\n",
    "        self.truncated = []\n",
    "        self.success, self.fail, self.rewards = None, None, None\n",
    "        if load_count == -1:\n",
    "            load_count = len(self.episodes)\n",
    "        for eps_id in tqdm(range(load_count)):\n",
    "            eps = self.episodes[eps_id]\n",
    "            if success_only:\n",
    "                assert (\n",
    "                    \"success\" in eps\n",
    "                ), \"episodes in this dataset do not have the success attribute, cannot load dataset with success_only=True\"\n",
    "                if not eps[\"success\"]:\n",
    "                    continue\n",
    "            trajectory = self.data[f\"traj_{eps['episode_id']}\"]\n",
    "            trajectory = load_h5_data(trajectory)\n",
    "            eps_len = len(trajectory[\"actions\"])\n",
    "\n",
    "            # exclude the final observation as most learning workflows do not use it\n",
    "            obs = common.index_dict_array(trajectory[\"obs\"], slice(eps_len))\n",
    "            if eps_id == 0:\n",
    "                self.obs = obs\n",
    "            else:\n",
    "                self.obs = common.append_dict_array(self.obs, obs)\n",
    "\n",
    "            self.actions.append(trajectory[\"actions\"])\n",
    "            self.terminated.append(trajectory[\"terminated\"])\n",
    "            self.truncated.append(trajectory[\"truncated\"])\n",
    "\n",
    "            # handle data that might optionally be in the trajectory\n",
    "            if \"rewards\" in trajectory:\n",
    "                if self.rewards is None:\n",
    "                    self.rewards = [trajectory[\"rewards\"]]\n",
    "                else:\n",
    "                    self.rewards.append(trajectory[\"rewards\"])\n",
    "            if \"success\" in trajectory:\n",
    "                if self.success is None:\n",
    "                    self.success = [trajectory[\"success\"]]\n",
    "                else:\n",
    "                    self.success.append(trajectory[\"success\"])\n",
    "            if \"fail\" in trajectory:\n",
    "                if self.fail is None:\n",
    "                    self.fail = [trajectory[\"fail\"]]\n",
    "                else:\n",
    "                    self.fail.append(trajectory[\"fail\"])\n",
    "\n",
    "        self.actions = np.vstack(self.actions)\n",
    "        self.terminated = np.concatenate(self.terminated)\n",
    "        self.truncated = np.concatenate(self.truncated)\n",
    "\n",
    "        if self.rewards is not None:\n",
    "            self.rewards = np.concatenate(self.rewards)\n",
    "        if self.success is not None:\n",
    "            self.success = np.concatenate(self.success)\n",
    "        if self.fail is not None:\n",
    "            self.fail = np.concatenate(self.fail)\n",
    "\n",
    "        def remove_np_uint16(x: Union[np.ndarray, dict]):\n",
    "            if isinstance(x, dict):\n",
    "                for k in x.keys():\n",
    "                    x[k] = remove_np_uint16(x[k])\n",
    "                return x\n",
    "            else:\n",
    "                if x.dtype == np.uint16:\n",
    "                    return x.astype(np.int32)\n",
    "                return x\n",
    "\n",
    "        # uint16 dtype is used to conserve disk space and memory\n",
    "        # you can optimize this dataset code to keep it as uint16 and process that\n",
    "        # dtype of data yourself. for simplicity we simply cast to a int32 so\n",
    "        # it can automatically be converted to torch tensors without complaint\n",
    "        self.obs = remove_np_uint16(self.obs)\n",
    "        \n",
    "        \n",
    "        # Initialize index lists and stat dicts\n",
    "        self.indices = create_sample_indices(\n",
    "            episode_ends=self.terminated, \n",
    "            sequence_length=self.pred_horizon,\n",
    "            pad_before=self.obs_horizon - 1,\n",
    "            pad_after=self.action_horizon - 1\n",
    "        )\n",
    "        \n",
    "        # normalize observations between -1 and 1\n",
    "        if self.normalize:\n",
    "            self.obs = normalize_data(self.obs, self.terminated)\n",
    "\n",
    "        \n",
    "        if device is not None:\n",
    "            self.actions = common.to_tensor(self.actions, device=device)\n",
    "            self.obs = common.to_tensor(self.obs, device=device)\n",
    "            self.terminated = common.to_tensor(self.terminated, device=device)\n",
    "            self.truncated = common.to_tensor(self.truncated, device=device)\n",
    "            if self.rewards is not None:\n",
    "                self.rewards = common.to_tensor(self.rewards, device=device)\n",
    "            if self.success is not None:\n",
    "                self.success = common.to_tensor(self.terminated, device=device)\n",
    "            if self.fail is not None:\n",
    "                self.fail = common.to_tensor(self.truncated, device=device)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.actions)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        buffer_start_idx, buffer_end_idx, sample_start_idx, sample_end_idx = self.indices[idx]\n",
    "        obs = sample_sequence(\n",
    "            train_data=self.obs, \n",
    "            sequence_length=self.pred_horizon,\n",
    "            buffer_start_idx=buffer_start_idx,\n",
    "            buffer_end_idx=buffer_end_idx,\n",
    "            sample_start_idx=sample_start_idx,\n",
    "            sample_end_idx=sample_end_idx\n",
    "        )\n",
    "        \n",
    "         # Sample actions directly (assuming they don't need normalization)\n",
    "        action = self.actions[buffer_start_idx + self.obs_horizon - 1 : buffer_end_idx + self.obs_horizon - 1 + self.action_horizon]\n",
    "\n",
    "        # If sequence is shorter than action_horizon, pad it\n",
    "        if len(action) < self.action_horizon:\n",
    "            padding = np.zeros((self.action_horizon - len(action),) + action.shape[1:], dtype=action.dtype)\n",
    "            action = np.concatenate([action, padding])\n",
    "\n",
    "        \n",
    "        action = common.to_tensor(action, device=self.device)\n",
    "        obs = common.to_tensor(obs, device=self.device)\n",
    "\n",
    "        res = dict(\n",
    "            obs=obs,\n",
    "            action=action,\n",
    "            terminated=self.terminated[idx],\n",
    "            truncated=self.truncated[idx],\n",
    "        )\n",
    "        if self.rewards is not None:\n",
    "            res.update(reward=self.rewards[idx])\n",
    "        if self.success is not None:\n",
    "            res.update(success=self.success[idx])\n",
    "        if self.fail is not None:\n",
    "            res.update(fail=self.fail[idx])\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ManiSkill Dataset\n",
    "dataset_file = '/content/drive/MyDrive/Data/Training/demos/PickCube-v1/rl/trajectory.state.pd_joint_delta_pos.h5'\n",
    "%ls /content/drive/MyDrive/Data/Training/demos/PickCube-v1/rl\n",
    "\n",
    "load_count = 10\n",
    "succes_only = True\n",
    "normalize = False # Normalization not working yet\n",
    "device = torch.device('cuda')\n",
    "\n",
    "pred_horizon = 16\n",
    "obs_horizon = 2\n",
    "action_horizon = 8\n",
    "#|o|o|                             observations: 2\n",
    "#| |a|a|a|a|a|a|a|a|               actions executed: 8\n",
    "#|p|p|p|p|p|p|p|p|p|p|p|p|p|p|p|p| actions predicted: 16\n",
    "\n",
    "\n",
    "# create dataset from file\n",
    "dataset = CustomManiSkillTrajectoryDataset(dataset_file, pred_horizon, obs_horizon, action_horizon, load_count, succes_only, normalize)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
