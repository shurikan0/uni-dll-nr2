{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install the package\n",
    "%pip install --upgrade mani_skill\n",
    "# install a version of torch that is compatible with your system\n",
    "%pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Command Line Options for panda:\n",
    "\n",
    "- `-e, --env-id`, type=$str$, default=\"PickCube-v1\", help=f\"Environment to run motion planning solver on\n",
    "- `-o, --obs-mode`, type=$str$, default=\"none\", help=\"Observation mode to use. Usually this is kept as 'none' as observations are not necesary to be stored, they can be replayed later via the mani_skill.trajectory.replay_trajectory script.\n",
    "- `-n, --num-traj`, type=$int$, default=10, help=\"Number of trajectories to generate.\"\n",
    "- `--only-count-success`, action=\"store_true\", help=\"If true, generates trajectories until num_traj of them are successful and only saves the successful trajectories/videos\"\n",
    "- `--reward-mode`, type=$str$\n",
    "- `-b, --sim-backend`, type=$str$, default=\"auto\", help=\"Which simulation backend to use. Can be 'auto', 'cpu', 'gpu'\"\n",
    "- `--render-mode`, type=$str$, default=\"rgb_array\", help=\"can be 'sensors' or 'rgb_array' which only affect what is saved to videos\"\n",
    "- `--vis`, action=\"store_true\", help=\"whether or not to open a GUI to visualize the solution live\"\n",
    "- `--save-video`, action=\"store_true\", help=\"whether or not to save videos locally\"\n",
    "- `--traj-name`, type=$str$, help=\"The name of the trajectory .h5 file that will be created.\"\n",
    "- `--shader`, default=\"default\", type=$str$, help=\"Change shader used for rendering. Default is 'default' which is very fast. Can also be 'rt' for ray tracing and generating photo-realistic renders. Can also be 'rt-fast' for a faster but lower quality ray-traced renderer\"\n",
    "- `--record-dir`, type=$str$, default=\"demos\", help=\"where to save the recorded trajectories\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environments\n",
    "\n",
    "- PickCube-v1\n",
    "- StackCube-v1\n",
    "- PegInsertionSide-v1\n",
    "- PlugCharger-v1\n",
    "- PushCube-v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!python -m mani_skill.examples.motionplanning.panda.run -e \"PickCube-v1\"\\\n",
    "    --num-traj 100 \\\n",
    "    --only-count-success \\ \n",
    "    --record-dir /content/drive/MyDrive/Data/Training/Generated \\\n",
    "    --traj-name data100 #File name is data100.h5\n",
    "    \n",
    "# The output will be saved in two files named data100.h5 and data100.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Command Line Options for replay:\n",
    "\n",
    "- `--save-traj`: save the replayed trajectory to the same folder as the original trajectory file.\n",
    "- `--target-control-mode`: The target control mode / action space to save into the trajectory file.\n",
    "- `--save-video`: Whether to save a video of the replayed trajectories\n",
    "- `--max-retry`: Max number of times to try and replay each trajectory\n",
    "- `--discard-timeout`: Whether to discard trajectories that time out due to the default environment's max episode steps config\n",
    "- `--allow-failure`: Whether to permit saving failed trajectories\n",
    "- `--vis`: Whether to open the GUI and show the replayed trajectories on a display\n",
    "- `--use-first-env-state`: Whether to use the first environment state of the given trajectory to initialize the environment\n",
    "- `--num-procs=10`: split trajectories to multiple processes (e.g., 10 processes) for acceleration. Note this is done via CPU parallelization, not GPU. This argument is also currently incompatible with using the GPU simulation to replay trajectories.\n",
    "- `--obs-mode=none`: specify the observation mode as `none`, i.e. not saving any observations.\n",
    "- `--obs-mode=rgbd`: (not included in the script above) specify the observation mode as `rgbd` to replay the trajectory. If `--save-traj`, the saved trajectory will contain the RGBD observations.\n",
    "- `--obs-mode=pointcloud`: (not included in the script above) specify the observation mode as `pointcloud`. We encourage you to further process the point cloud instead of using this point cloud directly (e.g. sub-sampling the pointcloud)\n",
    "- `--obs-mode=state`: (not included in the script above) specify the observation mode as `state`\n",
    "- `--use-env-states`: For each time step $t$, after replaying the action at this time step and obtaining a new observation at $t+1$, set the environment state at time $t+1$ as the recorded environment state at time $t+1$. This is necessary for successfully replaying trajectories for the tasks migrated from ManiSkill1.\n",
    "- `--count`: Number of demonstrations to replay before exiting. By default all demonstrations are replayed\n",
    "- `--shader`: \"Change shader used for rendering. Default is 'default' which is very fast. Can also be 'rt' for ray tracing and generating photo-realistic renders. Can also be 'rt-fast' for a faster but lower quality ray-traced renderer\"\n",
    "- `--render-mode`: The render mode used in the video saving\n",
    "- `-b, --sim-backend`: Which simulation backend to use. Can be 'auto', 'cpu', or 'gpu'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!python -m mani_skill.trajectory.replay_trajectory \\\n",
    "  --traj-path /content/drive/MyDrive/Data/Training/Generated/PickCube-v1/data100.h5 \\\n",
    "  --save-traj \\\n",
    "  --obs-mode rgbd \\\n",
    "  --sim-backend gpu\n",
    "\n",
    "# The output will be saved in two files named data100.pointcloud.h5 and data100.pointcloud.json"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
