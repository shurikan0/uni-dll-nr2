{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "busruHTsQiu_"
      },
      "source": [
        "### Loading Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kE3dI8B4QivA"
      },
      "outputs": [],
      "source": [
        "model_path = '../../Data/Checkpoints/model.pt'\n",
        "state_dict = torch.load(model_path, map_location='cuda')\n",
        "ema_noise_pred_net = noise_pred_net\n",
        "ema_noise_pred_net.load_state_dict(state_dict)\n",
        "print('Pretrained weights loaded.')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EWJGa5nJQivA"
      },
      "source": [
        "### Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7iDiG1b3QivA"
      },
      "outputs": [],
      "source": [
        "# limit enviornment interaction to 200 steps before termination\n",
        "result_path = \"../../Data/Results/videos\"\n",
        "\n",
        "env_id = \"PickCube-v1\"\n",
        "obs_mode = \"state_dict\"\n",
        "control_mode = \"pd_ee_delta_pos\"\n",
        "env = gym.make(env_id, obs_mode=obs_mode, control_mode=control_mode, render_mode='rgb_array')\n",
        "\n",
        "max_steps = 200\n",
        "\n",
        "# reset\n",
        "obs, info = env.reset()\n",
        "print(env.action_space)\n",
        "obs = get_observations(obs)\n",
        "obs = convert_observation(obs)\n",
        "\n",
        "# save observations\n",
        "obs_deque = collections.deque([obs] * obs_horizon, maxlen=obs_horizon)\n",
        "\n",
        "# save visualization\n",
        "imgs = []\n",
        "rewards = []\n",
        "done = False\n",
        "step_idx = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "88sCpU82QivB"
      },
      "outputs": [],
      "source": [
        "with tqdm(total=max_steps, desc=\"Eval\") as pbar:\n",
        "    while not done:\n",
        "        B = 1\n",
        "        # stack the last obs_horizon (2) number of observations\n",
        "        obs_seq = np.stack(obs_deque)\n",
        "        # normalize observation\n",
        "        #TODO: normalize observation\n",
        "        #nobs = normalize_data(obs_seq, stats=stats['obs'])\n",
        "        nobs = obs_seq\n",
        "        # device transfer\n",
        "        nobs = torch.from_numpy(nobs).to(device, dtype=torch.float32)\n",
        "\n",
        "        # infer action\n",
        "        with torch.no_grad():\n",
        "            # reshape observation to (B,obs_horizon*obs_dim)\n",
        "            obs_cond = nobs.unsqueeze(0).flatten(start_dim=1)\n",
        "\n",
        "            # initialize action from Guassian noise\n",
        "            noisy_action = torch.randn(\n",
        "                (B, pred_horizon, action_dim), device=device)\n",
        "            naction = noisy_action\n",
        "\n",
        "            # init scheduler\n",
        "            noise_scheduler.set_timesteps(num_diffusion_iters)\n",
        "\n",
        "            for k in noise_scheduler.timesteps:\n",
        "                # predict noise\n",
        "                noise_pred = ema_noise_pred_net(\n",
        "                    sample=naction,\n",
        "                    timestep=k,\n",
        "                    global_cond=obs_cond\n",
        "                )\n",
        "\n",
        "                # inverse diffusion step (remove noise)\n",
        "                naction = noise_scheduler.step(\n",
        "                    model_output=noise_pred,\n",
        "                    timestep=k,\n",
        "                    sample=naction\n",
        "                ).prev_sample\n",
        "\n",
        "        # unnormalize action\n",
        "        naction = naction.detach().to('cpu').numpy()\n",
        "        # (B, pred_horizon, action_dim)\n",
        "        naction = naction[0]\n",
        "        #TODO: unnormalize action\n",
        "        #action_pred = unnormalize_data(naction, stats=stats['action'])\n",
        "        action_pred = naction\n",
        "\n",
        "        # only take action_horizon number of actions\n",
        "        start = obs_horizon - 1\n",
        "        end = start + action_horizon\n",
        "        action = action_pred[start:end,:]\n",
        "\n",
        "        # execute action_horizon number of steps\n",
        "        # without replanning\n",
        "        for i in range(len(action)):\n",
        "            # stepping env\n",
        "            obs, reward, done, _, info = env.step(action[i])\n",
        "\n",
        "            # process observation\n",
        "            # From the observation dictionary, we concatenate all the observations\n",
        "            # as done in the training data\n",
        "            obs = get_observations(obs)\n",
        "            obs = convert_observation(obs)\n",
        "\n",
        "            # save observations\n",
        "            obs_deque.append(obs)\n",
        "\n",
        "            # and reward/vis\n",
        "            rewards.append(reward)\n",
        "            imgs.append(env.render())\n",
        "\n",
        "            # update progress bar\n",
        "            step_idx += 1\n",
        "            pbar.update(1)\n",
        "            pbar.set_postfix(reward=reward)\n",
        "            if step_idx > max_steps:\n",
        "                done = True\n",
        "            if done:\n",
        "                break\n",
        "# print out the maximum target coverage\n",
        "print('Score: ', max(rewards))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OINDDWvlQivC"
      },
      "source": [
        "### Save gif"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ELZDcAnQivC"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "from IPython.display import display, Image as IPImage\n",
        "import io\n",
        "\n",
        "print(\"Image shape:\", imgs[0].shape)  # Print shape to check if it's (H, W, 3) for RGB\n",
        "print(\"Image dtype:\", imgs[0].dtype)  # Should be uint8\n",
        "\n",
        "images = [Image.fromarray(img.squeeze(0).cpu().numpy()) for img in imgs]\n",
        "\n",
        "# Save to a bytes buffer\n",
        "buffer = io.BytesIO()\n",
        "images[0].save(buffer, format='GIF', save_all=True, append_images=images[1:], optimize=False, duration=50, loop=0)\n",
        "buffer.seek(0)\n",
        "\n",
        "# Save to a file\n",
        "with open('drive/MyDrive/Data/animation.gif', 'wb') as f:\n",
        "    f.write(buffer.getvalue())\n",
        "\n",
        "# Display the GIF (optional)\n",
        "display(IPImage(data=buffer.getvalue()))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "dlproject",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
